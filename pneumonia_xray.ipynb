{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, shutil\n",
    "original_dataset = 'chest_xray/'\n",
    "base_dir = 'chest_xray_small/'\n",
    "os.mkdir(base_dir)\n",
    "train_dir = os.path.join(base_dir, 'train')\n",
    "os.mkdir(train_dir)\n",
    "\n",
    "test_dir = os.path.join(base_dir, 'test')\n",
    "os.mkdir(test_dir)\n",
    "\n",
    "val_dir = os.path.join(base_dir, 'val')\n",
    "os.mkdir(val_dir)\n",
    "\n",
    "train_normal_dir = os.path.join(train_dir, 'normal')\n",
    "os.mkdir(train_normal_dir)\n",
    "\n",
    "train_pneumonia_dir = os.path.join(train_dir, 'pneumonia')\n",
    "os.mkdir(train_pneumonia_dir)\n",
    "\n",
    "test_normal_dir = os.path.join(test_dir, 'normal')\n",
    "os.mkdir(test_normal_dir)\n",
    "\n",
    "test_pneumonia_dir = os.path.join(test_dir, 'pneumonia')\n",
    "os.mkdir(test_pneumonia_dir)\n",
    "\n",
    "val_normal_dir = os.path.join(val_dir, 'normal')\n",
    "os.mkdir(val_normal_dir)\n",
    "\n",
    "val_pneumonia_dir = os.path.join(val_dir, 'pneumonia')\n",
    "os.mkdir(val_pneumonia_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total training normal images: 1342\n",
      "Total training pneumonia images: 3876\n",
      "Total test normal images: 234\n",
      "Total test pneumonia images: 390\n",
      "Total validation normal images: 9\n",
      "Total validation pneumonia images: 9\n"
     ]
    }
   ],
   "source": [
    "print('Total training normal images:', len(os.listdir('chest_xray/train/NORMAL')))\n",
    "print('Total training pneumonia images:', len(os.listdir('chest_xray/train/PNEUMONIA')))\n",
    "\n",
    "print('Total test normal images:', len(os.listdir('chest_xray/test/NORMAL')))\n",
    "print('Total test pneumonia images:', len(os.listdir('chest_xray/test/PNEUMONIA')))\n",
    "\n",
    "print('Total validation normal images:', len(os.listdir('chest_xray/val/NORMAL')))\n",
    "print('Total validation pneumonia images:', len(os.listdir('chest_xray/val/PNEUMONIA')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "fnames = ['NORMAL ({}).jpeg'.format(i) for i in range(1, 1301)]\n",
    "for fname in fnames:\n",
    "    src = os.path.join(original_dataset + 'train/NORMAL/', fname)\n",
    "    dst = os.path.join(train_normal_dir, fname)\n",
    "    shutil.copyfile(src, dst)\n",
    "    \n",
    "fnames = ['PNEUMONIA ({}).jpeg'.format(i) for i in range(1, 1301)]\n",
    "for fname in fnames:\n",
    "    src = os.path.join(original_dataset + 'train/PNEUMONIA/', fname)\n",
    "    dst = os.path.join(train_pneumonia_dir, fname)\n",
    "    shutil.copyfile(src, dst)\n",
    "    \n",
    "fnames = ['NORMAL ({}).jpeg'.format(i) for i in range(1, 231)]\n",
    "for fname in fnames:\n",
    "    src = os.path.join(original_dataset + 'test/NORMAL/', fname)\n",
    "    dst = os.path.join(test_normal_dir, fname)\n",
    "    shutil.copyfile(src, dst)\n",
    "    \n",
    "fnames = ['PNEUMONIA ({}).jpeg'.format(i) for i in range(1, 231)]\n",
    "for fname in fnames:\n",
    "    src = os.path.join(original_dataset + 'test/PNEUMONIA/', fname)\n",
    "    dst = os.path.join(test_pneumonia_dir, fname)\n",
    "    shutil.copyfile(src, dst)\n",
    "    \n",
    "fnames = ['NORMAL ({}).jpeg'.format(i) for i in range(1, 9)]\n",
    "for fname in fnames:\n",
    "    src = os.path.join(original_dataset + 'val/NORMAL/', fname)\n",
    "    dst = os.path.join(val_normal_dir, fname)\n",
    "    shutil.copyfile(src, dst)\n",
    "    \n",
    "fnames = ['PNEUMONIA ({}).jpeg'.format(i) for i in range(1, 9)]\n",
    "for fname in fnames:\n",
    "    src = os.path.join(original_dataset + 'val/PNEUMONIA/', fname)\n",
    "    dst = os.path.join(val_pneumonia_dir, fname)\n",
    "    shutil.copyfile(src, dst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import models\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.layers import Dropout \n",
    "from tensorflow.keras.layers import BatchNormalization\n",
    "\n",
    "model = models.Sequential()\n",
    "model.add(layers.Conv2D(16, (3,3),input_shape=(150,150,3), use_bias = False))\n",
    "model.add(layers.Activation('relu'))\n",
    "model.add(layers.BatchNormalization(scale = False, center=True))\n",
    "model.add(layers.MaxPooling2D(2,2))\n",
    "\n",
    "model.add(layers.Conv2D(32, (3,3), use_bias = False))\n",
    "model.add(layers.Activation('relu'))\n",
    "model.add(layers.BatchNormalization(scale = False, center=True))\n",
    "model.add(layers.MaxPooling2D(2,2))\n",
    "\n",
    "model.add(layers.Conv2D(64, (3,3), use_bias = False))\n",
    "model.add(layers.Activation('relu'))\n",
    "model.add(layers.BatchNormalization(scale = False, center=True))\n",
    "model.add(layers.MaxPooling2D(2,2))\n",
    "\n",
    "model.add(layers.Conv2D(128, (3,3),use_bias = False ))\n",
    "model.add(layers.Activation('relu'))\n",
    "model.add(layers.BatchNormalization(scale = False, center=True))\n",
    "model.add(layers.MaxPooling2D(2,2))\n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dropout(0.4))\n",
    "\n",
    "model.add(layers.Dense(512, activation = 'relu'))\n",
    "model.add(layers.Dense(1, activation = 'sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 340,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_17\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_50 (Conv2D)           (None, 148, 148, 16)      432       \n",
      "_________________________________________________________________\n",
      "activation_18 (Activation)   (None, 148, 148, 16)      0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_33 (Batc (None, 148, 148, 16)      48        \n",
      "_________________________________________________________________\n",
      "max_pooling2d_45 (MaxPooling (None, 74, 74, 16)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_51 (Conv2D)           (None, 72, 72, 32)        4608      \n",
      "_________________________________________________________________\n",
      "activation_19 (Activation)   (None, 72, 72, 32)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_34 (Batc (None, 72, 72, 32)        96        \n",
      "_________________________________________________________________\n",
      "max_pooling2d_46 (MaxPooling (None, 36, 36, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_52 (Conv2D)           (None, 34, 34, 64)        18432     \n",
      "_________________________________________________________________\n",
      "activation_20 (Activation)   (None, 34, 34, 64)        0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_35 (Batc (None, 34, 34, 64)        192       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_47 (MaxPooling (None, 17, 17, 64)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_53 (Conv2D)           (None, 15, 15, 128)       73728     \n",
      "_________________________________________________________________\n",
      "activation_21 (Activation)   (None, 15, 15, 128)       0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_36 (Batc (None, 15, 15, 128)       384       \n",
      "_________________________________________________________________\n",
      "max_pooling2d_48 (MaxPooling (None, 7, 7, 128)         0         \n",
      "_________________________________________________________________\n",
      "flatten_10 (Flatten)         (None, 6272)              0         \n",
      "_________________________________________________________________\n",
      "dropout_9 (Dropout)          (None, 6272)              0         \n",
      "_________________________________________________________________\n",
      "dense_20 (Dense)             (None, 512)               3211776   \n",
      "_________________________________________________________________\n",
      "dense_21 (Dense)             (None, 1)                 513       \n",
      "=================================================================\n",
      "Total params: 3,310,209\n",
      "Trainable params: 3,309,729\n",
      "Non-trainable params: 480\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 383,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.metrics import Precision\n",
    "from tensorflow.keras.metrics import Recall\n",
    "opt = Adam(lr = 1e-4)\n",
    "model.compile(loss='binary_crossentropy', optimizer= opt,\n",
    "                                                metrics=['acc',\n",
    "                                                        Precision(name='precision'),\n",
    "                                                        Recall(name = 'recall')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 384,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 2600 images belonging to 2 classes.\n",
      "Found 460 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "train_datagen = ImageDataGenerator(rescale = 1./255)\n",
    "validation_datagen = ImageDataGenerator(rescale = 1./255)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(train_dir, \n",
    "                                                   target_size = (150,150),\n",
    "                                                   batch_size = 20,\n",
    "                                                   class_mode = 'binary')\n",
    "\n",
    "val_generator = validation_datagen.flow_from_directory(test_dir, \n",
    "                                                   target_size = (150,150),\n",
    "                                                   batch_size = 20,\n",
    "                                                   class_mode = 'binary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 386,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    ""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 387,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tf_explain.callbacks.grad_cam import GradCAMCallback\n",
    "from tensorflow.keras import callbacks\n",
    "\n",
    "model_checkpoint = callbacks.ModelCheckpoint('xray_model.h5',\n",
    "                                                             save_best_only = True)\n",
    "\n",
    "early_stopping = callbacks.EarlyStopping(patience = 10,\n",
    "                                                         restore_best_weights =True\n",
    "                                                         )\n",
    "my_callbacks = [ \n",
    "                GradCAMCallback(validation_data= val_generator,\n",
    "                layer_name=\"dense_17\", \n",
    "                class_index=0,\n",
    "                output_dir='output_dir0',                                \n",
    "    ),\n",
    "                callbacks.TensorBoard(\n",
    "                log_dir='my_log_dir',\n",
    "                histogram_freq=1,\n",
    "                embeddings_freq=1)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 388,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "81/81 [==============================] - 77s 950ms/step - loss: 0.0209 - acc: 0.9926 - precision: 0.9938 - recall: 0.9913 - val_loss: 4.9361 - val_acc: 0.7500 - val_precision: 0.6667 - val_recall: 0.9855\n",
      "Epoch 2/50\n",
      "81/81 [==============================] - 80s 983ms/step - loss: 8.3545e-04 - acc: 0.9994 - precision: 1.0000 - recall: 0.9988 - val_loss: 4.5902 - val_acc: 0.7643 - val_precision: 0.6919 - val_recall: 0.9932\n",
      "Epoch 3/50\n",
      "81/81 [==============================] - 79s 975ms/step - loss: 7.6683e-04 - acc: 0.9994 - precision: 1.0000 - recall: 0.9987 - val_loss: 6.8427 - val_acc: 0.6750 - val_precision: 0.6062 - val_recall: 0.9856\n",
      "Epoch 4/50\n",
      "81/81 [==============================] - 76s 938ms/step - loss: 0.0035 - acc: 0.9988 - precision: 0.9988 - recall: 0.9988 - val_loss: 5.7309 - val_acc: 0.7321 - val_precision: 0.6404 - val_recall: 0.9848\n",
      "Epoch 5/50\n",
      "81/81 [==============================] - 75s 921ms/step - loss: 0.0075 - acc: 0.9981 - precision: 0.9976 - recall: 0.9988 - val_loss: 11.1688 - val_acc: 0.6321 - val_precision: 0.5636 - val_recall: 1.0000\n",
      "Epoch 6/50\n",
      "81/81 [==============================] - 75s 920ms/step - loss: 0.0038 - acc: 0.9988 - precision: 0.9988 - recall: 0.9988 - val_loss: 5.8635 - val_acc: 0.7000 - val_precision: 0.6290 - val_recall: 0.9858\n",
      "Epoch 7/50\n",
      "81/81 [==============================] - 75s 932ms/step - loss: 2.1222e-04 - acc: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 5.2075 - val_acc: 0.7250 - val_precision: 0.6219 - val_recall: 0.9921\n",
      "Epoch 8/50\n",
      "81/81 [==============================] - 75s 924ms/step - loss: 0.0017 - acc: 0.9994 - precision: 1.0000 - recall: 0.9988 - val_loss: 5.1444 - val_acc: 0.7429 - val_precision: 0.6570 - val_recall: 0.9927\n",
      "Epoch 9/50\n",
      "81/81 [==============================] - 75s 928ms/step - loss: 1.1518e-04 - acc: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 5.1221 - val_acc: 0.7321 - val_precision: 0.6411 - val_recall: 1.0000\n",
      "Epoch 10/50\n",
      "81/81 [==============================] - 75s 926ms/step - loss: 0.0021 - acc: 0.9988 - precision: 0.9988 - recall: 0.9988 - val_loss: 6.7048 - val_acc: 0.6929 - val_precision: 0.6188 - val_recall: 0.9928\n",
      "Epoch 11/50\n",
      "81/81 [==============================] - 79s 970ms/step - loss: 5.9550e-04 - acc: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 3.7953 - val_acc: 0.7786 - val_precision: 0.6891 - val_recall: 0.9852\n",
      "Epoch 12/50\n",
      "81/81 [==============================] - 75s 926ms/step - loss: 0.0019 - acc: 0.9994 - precision: 0.9988 - recall: 1.0000 - val_loss: 6.6128 - val_acc: 0.6929 - val_precision: 0.6126 - val_recall: 1.0000\n",
      "Epoch 13/50\n",
      "81/81 [==============================] - 75s 932ms/step - loss: 0.0016 - acc: 0.9994 - precision: 1.0000 - recall: 0.9988 - val_loss: 7.6329 - val_acc: 0.6857 - val_precision: 0.6239 - val_recall: 1.0000\n",
      "Epoch 14/50\n",
      "81/81 [==============================] - 77s 950ms/step - loss: 6.5152e-05 - acc: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 6.3909 - val_acc: 0.6964 - val_precision: 0.6222 - val_recall: 1.0000\n",
      "Epoch 15/50\n",
      "81/81 [==============================] - 76s 943ms/step - loss: 0.0039 - acc: 0.9981 - precision: 0.9975 - recall: 0.9988 - val_loss: 2.7706 - val_acc: 0.8179 - val_precision: 0.7235 - val_recall: 0.9685\n",
      "Epoch 16/50\n",
      "81/81 [==============================] - 80s 988ms/step - loss: 1.8386e-04 - acc: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 4.5398 - val_acc: 0.7607 - val_precision: 0.6768 - val_recall: 0.9781\n",
      "Epoch 17/50\n",
      "81/81 [==============================] - 87s 1s/step - loss: 6.2241e-05 - acc: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 5.8158 - val_acc: 0.7179 - val_precision: 0.6532 - val_recall: 0.9864\n",
      "Epoch 18/50\n",
      "81/81 [==============================] - 85s 1s/step - loss: 2.8510e-04 - acc: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 4.6136 - val_acc: 0.7500 - val_precision: 0.6730 - val_recall: 0.9930\n",
      "Epoch 19/50\n",
      "81/81 [==============================] - 86s 1s/step - loss: 5.0906e-05 - acc: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 5.3811 - val_acc: 0.7500 - val_precision: 0.6714 - val_recall: 0.9930\n",
      "Epoch 20/50\n",
      "81/81 [==============================] - 82s 1s/step - loss: 5.9272e-05 - acc: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 5.2019 - val_acc: 0.7393 - val_precision: 0.6588 - val_recall: 0.9929\n",
      "Epoch 21/50\n",
      "81/81 [==============================] - 84s 1s/step - loss: 8.3243e-05 - acc: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 5.3609 - val_acc: 0.7250 - val_precision: 0.6532 - val_recall: 1.0000\n",
      "Epoch 22/50\n",
      "81/81 [==============================] - 84s 1s/step - loss: 0.0033 - acc: 0.9988 - precision: 0.9987 - recall: 0.9987 - val_loss: 4.4264 - val_acc: 0.7607 - val_precision: 0.6734 - val_recall: 0.9853\n",
      "Epoch 23/50\n",
      "81/81 [==============================] - 94s 1s/step - loss: 2.7324e-04 - acc: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 4.1154 - val_acc: 0.7857 - val_precision: 0.7079 - val_recall: 0.9931\n",
      "Epoch 24/50\n",
      "81/81 [==============================] - 85s 1s/step - loss: 3.5426e-05 - acc: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 4.8227 - val_acc: 0.7321 - val_precision: 0.6473 - val_recall: 0.9853\n",
      "Epoch 25/50\n",
      "81/81 [==============================] - 89s 1s/step - loss: 3.9842e-04 - acc: 1.0000 - precision: 1.0000 - recall: 1.0000 - val_loss: 5.4734 - val_acc: 0.7143 - val_precision: 0.6441 - val_recall: 0.9931\n"
     ]
    }
   ],
   "source": [
    "TRAINING_IMAGES_COUNT = 2600\n",
    "VALIDATION_IMAGES_COUNT = 460\n",
    "BS = 32\n",
    "EPOCHS = 50\n",
    "history = model.fit_generator(train_generator,\n",
    "                             steps_per_epoch = TRAINING_IMAGES_COUNT // BS,\n",
    "                             epochs = EPOCHS,\n",
    "                             validation_data = val_generator ,\n",
    "                              validation_steps = VALIDATION_IMAGES_COUNT // BS,\n",
    "                             callbacks = [early_stopping, model_checkpoint])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 16 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "test_datagen = ImageDataGenerator(rescale = 1./255)\n",
    "test_generator = test_datagen.flow_from_directory(val_dir, \n",
    "                                                   target_size = (150,150),\n",
    "                                                   batch_size = 20,\n",
    "                                                   class_mode = 'binary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 1/25 [>.............................] - ETA: 0s - loss: 0.6165 - acc: 0.8125 - precision: 1.0000 - recall): 0.6250WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 25 batches). You may need to use the repeat() function when building your dataset.\n",
      " 1/25 [>.............................] - 0s 14ms/step - loss: 0.6165 - acc: 0.8125 - precision: 1.0000 - recall): 0.6250\n"
     ]
    }
   ],
   "source": [
    "predIs = model.evaluate(test_generator, steps=25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
